{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhZkww2Yrqbkc+to+JN8pp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guru-180188/Projects/blob/main/GAN_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "TXMOVtpSfHiK",
        "outputId": "9f7c6265-1e8f-4d52-be2c-127ad31c9f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step\n",
            ">1, 1/234, d=0.708, g=0.756\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">1, 2/234, d=0.661, g=0.849\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            ">1, 3/234, d=0.634, g=0.928\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            ">1, 4/234, d=0.620, g=0.921\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            ">1, 5/234, d=0.639, g=0.786\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            ">1, 6/234, d=0.648, g=0.700\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">1, 7/234, d=0.622, g=0.691\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            ">1, 8/234, d=0.579, g=0.696\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            ">1, 9/234, d=0.535, g=0.702\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            ">1, 10/234, d=0.495, g=0.706\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            ">1, 11/234, d=0.448, g=0.712\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0bf366cec482>\u001b[0m in \u001b[0;36m<cell line: 181>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0bf366cec482>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m    151\u001b[0m                         \u001b[0mX_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                         \u001b[0;31m# generate 'fake' examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                         \u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                         \u001b[0;31m# create training set for the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0bf366cec482>\u001b[0m in \u001b[0;36mgenerate_fake_samples\u001b[0;34m(g_model, latent_dim, n_samples)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# generate points in latent space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;31m# predict outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0bf366cec482>\u001b[0m in \u001b[0;36mgenerate_latent_points\u001b[0;34m(latent_dim, n_samples)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# generate points in the latent space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# reshape into a batch of inputs for the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/\n",
        "# example of training a gan on mnist\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(28,28,1)):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "\tmodel = Sequential()\n",
        "\t# foundation for 7x7 image\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((7, 7, 128)))\n",
        "\t# upsample to 14x14\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 28x28\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
        "\treturn model\n",
        "\n",
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\td_model.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(g_model)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(d_model)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "# load and prepare mnist training images\n",
        "def load_real_samples():\n",
        "\t# load mnist dataset\n",
        "\t(trainX, _), (_, _) = load_data()\n",
        "\t# expand to 3d, e.g. add channels dimension\n",
        "\tX = expand_dims(trainX, axis=-1)\n",
        "\t# convert from unsigned ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [0,1]\n",
        "\tX = X / 255.0\n",
        "\treturn X\n",
        "\n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = g_model.predict(x_input)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# create and save a plot of generated images (reversed grayscale)\n",
        "def save_plot(examples, epoch, n=10):\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "\t# save plot to file\n",
        "\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tpyplot.savefig(filename)\n",
        "\tpyplot.close()\n",
        "\n",
        "# evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "\t# prepare real samples\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t# evaluate discriminator on real examples\n",
        "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\t# prepare fake examples\n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# evaluate discriminator on fake examples\n",
        "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\t# summarize discriminator performance\n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\t# save plot\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\t# save the generator model tile file\n",
        "\tfilename = 'generator_model_%03d.h5' % (epoch + 1)\n",
        "\tg_model.save(filename)\n",
        "\n",
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# enumerate batches over the training set\n",
        "\t\tfor j in range(bat_per_epo):\n",
        "\t\t\t# get randomly selected 'real' samples\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# generate 'fake' examples\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# create training set for the discriminator\n",
        "\t\t\tX, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "\t\t\t# update discriminator model weights\n",
        "\t\t\td_loss, _ = d_model.train_on_batch(X, y)\n",
        "\t\t\t# prepare points in latent space as input for the generator\n",
        "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\t# create inverted labels for the fake samples\n",
        "\t\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t\t# update the generator via the discriminator's error\n",
        "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t\t# summarize loss on this batch\n",
        "\t\t\tprint('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "\t\t# evaluate the model performance, sometimes\n",
        "\t\tif (i+1) % 10 == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
        "\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "d_model = define_discriminator()\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Sure, let's go through the code line by line and explain each part:\n",
        "\n",
        "```python\"\"\"\n",
        "# Import necessary libraries\n",
        "from numpy import expand_dims, zeros, ones, vstack, randn, randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n",
        "from matplotlib import pyplot\n",
        "\"\"\"\n",
        "\n",
        "The code begins by importing the required libraries: NumPy for numerical operations, Keras for building and training the neural network models, and Matplotlib for plotting.\n",
        "\n",
        "```python\"\"\"\n",
        "# Define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(28,28,1)):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    return model\n",
        "\"\"\"\n",
        "\n",
        "The `define_discriminator` function creates the discriminator model. It's a convolutional neural network (CNN) that takes a 28x28 grayscale image as input and outputs a binary classification (real or fake). The architecture consists of two convolutional layers with LeakyReLU activation and dropout to prevent overfitting. After flattening, a dense layer with a sigmoid activation is used to predict the binary output. The model is compiled with the Adam optimizer and binary cross-entropy loss.\n",
        "\n",
        "```python\"\"\"\n",
        "# Define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    n_nodes = 128 * 7 * 7\n",
        "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
        "    return model\n",
        "\"\"\"\n",
        "\n",
        "The `define_generator` function creates the generator model. It takes a latent_dim as input, which represents the size of the random noise vector (latent space). The generator starts with a dense layer that transforms the random noise into a higher-dimensional representation. It then reshapes this representation into a 7x7x128 tensor. Two transpose convolutional layers are used to gradually upsample the tensor to 28x28 size, and finally, the generator outputs a 28x28 grayscale image using a sigmoid activation.\n",
        "\n",
        "```python\"\"\"\n",
        "# Define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "    d_model.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(g_model)\n",
        "    model.add(d_model)\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "The `define_gan` function creates the GAN model by combining the generator and discriminator. The discriminator's weights are set to non-trainable to avoid updating them during the generator training. The generator is added as the first layer of the GAN, followed by the discriminator. The GAN is compiled with the Adam optimizer and binary cross-entropy loss.\n",
        "\n",
        "```python\"\"\"\n",
        "# Load and prepare MNIST training images\n",
        "def load_real_samples():\n",
        "    (trainX, _), (_, _) = load_data()\n",
        "    X = expand_dims(trainX, axis=-1)\n",
        "    X = X.astype('float32')\n",
        "    X = X / 255.0\n",
        "    return X\n",
        "\"\"\"\n",
        "\n",
        "The `load_real_samples` function loads the MNIST dataset and prepares the images. It loads the dataset, expands the dimensions to add a channel dimension (since the original dataset is grayscale), converts pixel values to floating-point numbers, and scales them to the range [0, 1].\n",
        "\n",
        "(Continued in the next message due to character limit)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Continuing from the previous explanation:\n",
        "\n",
        "```python\"\"\"\n",
        "# Select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    X = dataset[ix]\n",
        "    y = ones((n_samples, 1))\n",
        "    return X, y\n",
        "\"\"\"\n",
        "\n",
        "The `generate_real_samples` function selects a random batch of real images from the dataset. It takes the prepared dataset and the number of samples to generate as input. It randomly selects indices (ix) from the dataset and retrieves the corresponding images (X). For each real image, it assigns a \"real\" class label (1).\n",
        "\n",
        "```python\"\"\"\n",
        "# Generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input\n",
        "\"\"\"\n",
        "\n",
        "The `generate_latent_points` function generates random points in the latent space (random noise) as input for the generator. It takes the size of the latent space (latent_dim) and the number of samples to generate (n_samples) as input. It creates a random vector (x_input) of shape (latent_dim * n_samples) using NumPy's `randn` function, and then reshapes it into a batch of inputs for the generator.\n",
        "\n",
        "```python\"\"\"\n",
        "# Use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    X = g_model.predict(x_input)\n",
        "    y = zeros((n_samples, 1))\n",
        "    return X, y\n",
        "\"\"\"\n",
        "\n",
        "The `generate_fake_samples` function uses the generator to produce fake images given random points in the latent space. It takes the generator model, the size of the latent space (latent_dim), and the number of samples to generate (n_samples) as input. It first generates random points in the latent space using `generate_latent_points`. Then, it passes these points through the generator (`g_model.predict`) to produce fake images (X). For each fake image, it assigns a \"fake\" class label (0).\n",
        "\n",
        "```python\"\"\"\n",
        "# Create and save a plot of generated images (reversed grayscale)\n",
        "def save_plot(examples, epoch, n=10):\n",
        "    for i in range(n * n):\n",
        "        pyplot.subplot(n, n, 1 + i)\n",
        "        pyplot.axis('off')\n",
        "        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "    filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "    pyplot.savefig(filename)\n",
        "    pyplot.close()\n",
        "\"\"\"\n",
        "\n",
        "The `save_plot` function creates a grid plot of generated images and saves it as a PNG file. It takes the generated images (examples), the current epoch number (epoch), and the number of images to display in each row/column (n). The function iterates through the generated images, creates a subplot for each image, and sets the axis off. It then displays the image using a reversed grayscale color map (`gray_r`). Finally, it saves the plot to a file named with the epoch number.\n",
        "\n",
        "```python\"\"\"\n",
        "# Evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "    save_plot(x_fake, epoch)\n",
        "    filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
        "    g_model.save(filename)\n",
        "\"\"\"\n",
        "\n",
        "The `summarize_performance` function evaluates the discriminator's performance, plots generated images, and saves the generator model at the specified epoch. It takes the current epoch number (epoch), the generator model (g_model), the discriminator model (d_model), the dataset, the size of the latent space (latent_dim), and the number of samples to generate (n_samples) as input.\n",
        "\n",
        "The function first generates a batch of real samples and evaluates the discriminator's accuracy on real data. Then, it generates a batch of fake samples using the generator and evaluates the discriminator's accuracy on the fake data. It prints the accuracy of the discriminator on both real and fake samples.\n",
        "\n",
        "Next, it calls the `save_plot` function to create and save a grid plot of the generated fake images. Finally, it saves the generator model to a file with a name that includes the epoch number.\n",
        "\n",
        "```python\"\"\"\n",
        "# Train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=25, n_batch=256):\n",
        "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "    half_batch = int(n_batch / 2)\n",
        "    for i in range(n_epochs):\n",
        "        for j in range(bat_per_epo):\n",
        "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "            d_loss, _ = d_model.train_on_batch(X, y)\n",
        "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "            y_gan = ones((n_batch, 1))\n",
        "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "        if (i+1) % 10 == 0:\n",
        "            summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
        "\"\"\"\n",
        "\n",
        "The `train` function is responsible for training the GAN. It takes the generator model (g_model), discriminator model (d_model), GAN model (gan_model), the dataset, the size of the latent space (latent_dim), the number of epochs to train (n_epochs), and the batch size (n_batch) as input.\n",
        "\n",
        "The function starts by calculating the number of batches per epoch (bat_per_epo) and half of the batch size (half_batch). Then, it runs a loop for the specified number of epochs.\n",
        "\n",
        "Within each epoch, it iterates over the batches in the training dataset. For each batch, it generates a batch of real and fake samples using `generate_real_samples` and `generate_fake_samples`. It then stacks the real and fake samples along with their corresponding labels to create a training set for the discriminator.\n",
        "\n",
        "Next, it trains the discriminator model on the batch of real and fake samples, updating its weights. It then generates a batch of points in the latent space and sets the target labels to \"real\" (1) to trick the generator.\n",
        "\n",
        "Finally, it trains the GAN model on the batch of latent space points with the inverted labels, updating the generator's weights. During training,\n",
        "\n",
        " it prints the discriminator and generator losses for each batch.\n",
        "\n",
        "Every 10 epochs, the `summarize_performance` function is called to evaluate the current performance of the GAN, plot generated images, and save the generator model.\n",
        "\n",
        "Overall, the code implements a GAN for generating handwritten digits similar to those in the MNIST dataset and trains it for a specified number of epochs.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-rKynrMdfrwR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}